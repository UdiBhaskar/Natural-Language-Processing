{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gR5FuSTAp5f"
   },
   "source": [
    "# Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cW3H5BiGAp5g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\tf2\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "##imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjWmQ1kLAp5k"
   },
   "outputs": [],
   "source": [
    "##getting data from https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/kernels?sortBy=voteCount&group=everyone&pageSize=20&datasetId=134715\n",
    "data_imdb = pd.read_csv(r'IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "BXH4zq3nAp5n",
    "outputId": "8cf87920-7d1e-4cce-97e0-e50201a9bc53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "data_imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNpC5fLrAp5r"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Cleans the text data'''\n",
    "    ##remove html tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-vpKZILAp5v"
   },
   "outputs": [],
   "source": [
    "data_imdb['review'] = data_imdb['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "mBp0y777Ap5x",
    "outputId": "0367c81e-98fb-45f1-f8f1-b6986cf4e50e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pk5I1vvoAp51"
   },
   "source": [
    "We will get the reviews text and train the word2vec using gensim and tensorflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncViAtOlAp51"
   },
   "source": [
    "## Word2Vec using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AryEOckKAp53"
   },
   "outputs": [],
   "source": [
    "##getting sentence wise data\n",
    "list_sents = [nltk.word_tokenize(sent) for sent_tok in data_imdb.review for sent in nltk.sent_tokenize(sent_tok)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1mU8AJTAp56"
   },
   "outputs": [],
   "source": [
    "##import gensim\n",
    "from gensim.models import Word2Vec\n",
    "##word2vec model ##this may take some time to execute. \n",
    "word2vec_model = Word2Vec(list_sents,##list of sentences, if you don;t have all the data in RAM, you can give file name to corpus_file \n",
    "                          size=50, ##output size of word emebedding \n",
    "                          window=4, ##window size\n",
    "                          min_count=1, ## ignors all the words with total frquency lower than this\n",
    "                          workers=5, ##number of workers to use\n",
    "                          sg=1, ## skip gram\n",
    "                          hs=0, ## 1 --> hierarchical, 0 --> Negative sampling\n",
    "                          negative=5, ##How many negative samples\n",
    "                          alpha=0.03, ##The initial learning rate\n",
    "                          min_alpha=0.0001, ##Learning rate will linearly drop to min_alpha as training progresses.\n",
    "                          seed = 54, ##random seed\n",
    "                          iter=10,\n",
    "                         compute_loss=True)##number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_iAdxfqAp58",
    "outputId": "d139e750-a089-49dd-e409-3de643091988"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8166441 , -0.9765926 ,  0.6889766 , -0.15333726,  0.32603604,\n",
       "        0.34232008,  0.1982183 ,  0.45404515, -0.27898434,  0.37556762,\n",
       "        0.32830954,  0.4677273 , -0.15545918,  0.37998974,  0.4832581 ,\n",
       "        0.5520326 ,  0.01102996, -0.73172736,  0.32559022,  0.0229142 ,\n",
       "       -0.11138992,  0.13175151,  0.1802587 ,  0.10442656,  0.7089927 ,\n",
       "        0.36721262,  0.2659526 ,  0.01060779,  0.09674501, -0.07720459,\n",
       "       -0.1431406 , -0.04784476, -0.19753593, -0.01077123,  0.20721771,\n",
       "       -0.308895  ,  0.3016016 ,  0.27222142, -0.04451592,  0.10112086,\n",
       "        0.1615566 , -0.2219478 ,  0.14381573,  0.41217476,  0.08204534,\n",
       "       -0.30486378, -0.279101  , -0.06951407,  1.008649  ,  0.46495098],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##getting a word vector\n",
    "word2vec_model.wv['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwD7KOJVAp5-",
    "outputId": "d1d3bd90-62a7-461e-dd55-00ffc74cfabb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.9484750628471375),\n",
       " ('film.it', 0.8743568658828735),\n",
       " ('film.but', 0.8640142679214478),\n",
       " ('movie.it', 0.862943708896637),\n",
       " ('movie.this', 0.8548593521118164),\n",
       " ('thing.i', 0.8546229004859924),\n",
       " ('one.it', 0.8504076600074768),\n",
       " ('film.what', 0.8469654321670532),\n",
       " ('train-wreck', 0.845355212688446),\n",
       " ('it.overall', 0.8342217206954956)]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69231lTQAp6B",
    "outputId": "b8251740-b966-4b19-d3a4-c69eef8e74e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-ascension', 0.3580598533153534),\n",
       " ('4.5*/5.0*', 0.2924154996871948),\n",
       " ('aghhh', 0.27601221203804016),\n",
       " ('x100', 0.2736707031726837),\n",
       " ('yikes.7/10', 0.2691265344619751),\n",
       " ('gwr', 0.2680243253707886),\n",
       " ('stupid.6', 0.26558661460876465),\n",
       " (\"'aimee\", 0.25137749314308167),\n",
       " ('purrrrrrrrrrrrrrrr', 0.24971842765808105),\n",
       " ('parhat', 0.24267500638961792)]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(negative='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4rEk1Z8Ap6E"
   },
   "outputs": [],
   "source": [
    "##saving \n",
    "word2vec_model.save('w2vmodel_gensim_model/w2vmodel')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "W2V.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
